#!/usr/bin/env python3
"""
æ’­å®¢è½¬å½•æ¨¡å— - æ”¯æŒå¤šç§è½¬å½•æ–¹æ¡ˆ
1. OpenAI Whisper APIï¼ˆåœ¨çº¿ï¼‰
2. faster-whisperï¼ˆæœ¬åœ°ï¼Œè½»é‡ï¼‰
3. whisper.cppï¼ˆçº¯CPUï¼‰
4. ç®€åŒ–æ¨¡å¼ï¼ˆä»…ä¸‹è½½ï¼‰
"""

import os
import sys
import tempfile
import subprocess
from pathlib import Path
from config import (
    TRANSCRIPTION_MODE,
    OPENAI_API_KEY,
    OPENAI_WHISPER_MODEL,
    FASTER_WHISPER_MODEL_SIZE,
    FASTER_WHISPER_DEVICE,
    FASTER_WHISPER_COMPUTE_TYPE,
    TRANSCRIPT_LANGUAGE,
)


class TranscriptionError(Exception):
    """è½¬å½•é”™è¯¯å¼‚å¸¸"""

    pass


class TranscriptionManager:
    """è½¬å½•ç®¡ç†å™¨ - æ ¹æ®é…ç½®é€‰æ‹©æœ€ä½³è½¬å½•æ–¹æ¡ˆ"""

    def __init__(self):
        self.mode = TRANSCRIPTION_MODE
        self.language = TRANSCRIPT_LANGUAGE
        self.available_modes = self._detect_available_modes()

    def _detect_available_modes(self):
        """æ£€æµ‹å¯ç”¨çš„è½¬å½•æ¨¡å¼"""
        available = ["simplified"]  # ç®€åŒ–æ¨¡å¼æ€»æ˜¯å¯ç”¨

        # æ£€æŸ¥OpenAI API
        if OPENAI_API_KEY and OPENAI_API_KEY.strip():
            available.append("openai_api")

        # æ£€æŸ¥faster-whisper
        try:
            import faster_whisper

            available.append("faster_whisper")
        except ImportError:
            pass

        # æ£€æŸ¥whisper.cpp
        if self._check_whisper_cpp():
            available.append("whisper_cpp")

        # æ£€æŸ¥åŽŸå§‹whisperï¼ˆå¤‡ç”¨ï¼‰
        try:
            import whisper

            available.append("whisper")
        except ImportError:
            pass

        return available

    def _check_whisper_cpp(self):
        """æ£€æŸ¥whisper.cppæ˜¯å¦å¯ç”¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†whisper-cpp
            result = subprocess.run(
                ["which", "whisper-cpp"], capture_output=True, text=True
            )
            return result.returncode == 0
        except:
            return False

    def transcribe(self, audio_path, podcast_name="", episode_title=""):
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            podcast_name: æ’­å®¢åç§°ï¼ˆç”¨äºŽé”™è¯¯ä¿¡æ¯ï¼‰
            episode_title: æœŸæ•°æ ‡é¢˜ï¼ˆç”¨äºŽé”™è¯¯ä¿¡æ¯ï¼‰

        Returns:
            str: è½¬å½•æ–‡æœ¬
        """
        print(f"ðŸŽ¤ å¼€å§‹è½¬å½•: {episode_title or Path(audio_path).name}")

        # æŒ‰ä¼˜å…ˆçº§å°è¯•å¯ç”¨æ¨¡å¼
        modes_to_try = [self.mode] + [m for m in self.available_modes if m != self.mode]

        for mode in modes_to_try:
            try:
                if mode == "openai_api":
                    return self._transcribe_openai_api(audio_path)
                elif mode == "faster_whisper":
                    return self._transcribe_faster_whisper(audio_path)
                elif mode == "whisper_cpp":
                    return self._transcribe_whisper_cpp(audio_path)
                elif mode == "whisper":
                    return self._transcribe_whisper(audio_path)
                elif mode == "simplified":
                    return self._simplified_transcription(
                        audio_path, podcast_name, episode_title
                    )
            except Exception as e:
                print(f"âš ï¸  {mode} æ¨¡å¼å¤±è´¥: {e}")
                continue

        # æ‰€æœ‰æ¨¡å¼éƒ½å¤±è´¥
        error_msg = f"âŒ æ‰€æœ‰è½¬å½•æ¨¡å¼éƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®"
        raise TranscriptionError(error_msg)

    def _transcribe_openai_api(self, audio_path):
        """ä½¿ç”¨OpenAI Whisper APIè½¬å½•éŸ³é¢‘"""
        print("ðŸ”— ä½¿ç”¨OpenAI Whisper APIè½¬å½•...")

        if not OPENAI_API_KEY or not OPENAI_API_KEY.strip():
            raise TranscriptionError("OpenAI API keyæœªé…ç½®")

        try:
            from openai import OpenAI

            client = OpenAI(api_key=OPENAI_API_KEY)

            with open(audio_path, "rb") as audio_file:
                transcript = client.audio.transcriptions.create(
                    model=OPENAI_WHISPER_MODEL,
                    file=audio_file,
                    language=self.language,
                    response_format="text",
                )

            print(f"âœ… OpenAIè½¬å½•å®Œæˆï¼Œé•¿åº¦: {len(transcript)} å­—ç¬¦")
            return transcript

        except ImportError:
            raise TranscriptionError("æœªå®‰è£…openaiåº“: pip install openai")
        except Exception as e:
            raise TranscriptionError(f"OpenAI APIé”™è¯¯: {e}")

    def _transcribe_faster_whisper(self, audio_path):
        """ä½¿ç”¨faster-whisperè½¬å½•éŸ³é¢‘"""
        print(f"âš¡ ä½¿ç”¨faster-whisperè½¬å½• (æ¨¡åž‹: {FASTER_WHISPER_MODEL_SIZE})...")

        try:
            from faster_whisper import WhisperModel

            # åŠ è½½æ¨¡åž‹
            model = WhisperModel(
                FASTER_WHISPER_MODEL_SIZE,
                device=FASTER_WHISPER_DEVICE,
                compute_type=FASTER_WHISPER_COMPUTE_TYPE,
            )

            # è½¬å½•éŸ³é¢‘
            segments, info = model.transcribe(
                audio_path, language=self.language, beam_size=5, vad_filter=True
            )

            # åˆå¹¶æ‰€æœ‰ç‰‡æ®µ
            transcript = "".join(segment.text for segment in segments)

            print(f"âœ… faster-whisperè½¬å½•å®Œæˆï¼Œé•¿åº¦: {len(transcript)} å­—ç¬¦")
            print(
                f"   æ£€æµ‹è¯­è¨€: {info.language}, æ¦‚çŽ‡: {info.language_probability:.2f}"
            )

            return transcript

        except ImportError:
            raise TranscriptionError("æœªå®‰è£…faster-whisper: pip install faster-whisper")
        except Exception as e:
            raise TranscriptionError(f"faster-whisperé”™è¯¯: {e}")

    def _transcribe_whisper_cpp(self, audio_path):
        """ä½¿ç”¨whisper.cppè½¬å½•éŸ³é¢‘"""
        print("ðŸ”§ ä½¿ç”¨whisper.cppè½¬å½•...")

        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as f:
            output_file = f.name

        try:
            # æž„å»ºå‘½ä»¤
            cmd = [
                "whisper-cpp",
                "-m",
                "models/ggml-base.bin",  # éœ€è¦æå‰ä¸‹è½½æ¨¡åž‹
                "-f",
                audio_path,
                "-l",
                self.language,
                "-otxt",
                "-of",
                output_file.replace(".txt", ""),  # åŽ»æŽ‰æ‰©å±•å
            ]

            # æ‰§è¡Œè½¬å½•
            result = subprocess.run(cmd, capture_output=True, text=True)

            if result.returncode != 0:
                raise TranscriptionError(f"whisper.cppæ‰§è¡Œå¤±è´¥: {result.stderr}")

            # è¯»å–è½¬å½•ç»“æžœ
            with open(output_file, "r", encoding="utf-8") as f:
                transcript = f.read()

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(output_file)

            print(f"âœ… whisper.cppè½¬å½•å®Œæˆï¼Œé•¿åº¦: {len(transcript)} å­—ç¬¦")
            return transcript

        except FileNotFoundError:
            raise TranscriptionError(
                "whisper-cppæœªå®‰è£…ï¼Œè¯·å‚è€ƒ: https://github.com/ggerganov/whisper.cpp"
            )
        except Exception as e:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(output_file):
                os.unlink(output_file)
            raise TranscriptionError(f"whisper.cppé”™è¯¯: {e}")

    def _transcribe_whisper(self, audio_path):
        """ä½¿ç”¨åŽŸå§‹whisperè½¬å½•éŸ³é¢‘ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        print("ðŸŽµ ä½¿ç”¨OpenAI Whisperè½¬å½•...")

        try:
            import whisper

            # åŠ è½½æ¨¡åž‹
            model = whisper.load_model("base")

            # è½¬å½•éŸ³é¢‘
            result = model.transcribe(
                audio_path, language=self.language, fp16=False  # CPUæ¨¡å¼
            )

            transcript = result["text"]

            print(f"âœ… Whisperè½¬å½•å®Œæˆï¼Œé•¿åº¦: {len(transcript)} å­—ç¬¦")
            return transcript

        except ImportError:
            raise TranscriptionError("æœªå®‰è£…whisper: pip install openai-whisper")
        except Exception as e:
            raise TranscriptionError(f"Whisperé”™è¯¯: {e}")

    def _simplified_transcription(self, audio_path, podcast_name, episode_title):
        """ç®€åŒ–æ¨¡å¼ - ä¸å®žé™…è½¬å½•ï¼Œè¿”å›žå ä½æ–‡æœ¬"""
        print("ðŸ“ ä½¿ç”¨ç®€åŒ–æ¨¡å¼ï¼ˆè·³è¿‡å®žé™…è½¬å½•ï¼‰...")

        file_size = os.path.getsize(audio_path)
        file_size_mb = file_size / (1024 * 1024)

        transcript = f"""
# æ’­å®¢éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯

**æ’­å®¢åç§°**: {podcast_name}
**æœŸæ•°æ ‡é¢˜**: {episode_title}
**éŸ³é¢‘æ–‡ä»¶**: {Path(audio_path).name}
**æ–‡ä»¶å¤§å°**: {file_size_mb:.2f} MB
**å¤„ç†æ—¶é—´**: å·²ä¸‹è½½ï¼Œç­‰å¾…è½¬å½•

## ðŸ“‹ è½¬å½•çŠ¶æ€
å½“å‰ä½¿ç”¨ç®€åŒ–æ¨¡å¼ï¼Œæœªè¿›è¡Œå®žé™…éŸ³é¢‘è½¬å½•ã€‚

## ðŸ”§ å¯ç”¨å®Œæ•´è½¬å½•çš„æ–¹æ³•

### æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨OpenAI Whisper APIï¼ˆæŽ¨èï¼‰
1. èŽ·å–OpenAI API key: https://platform.openai.com/api-keys
2. åœ¨ `config.py` ä¸­è®¾ç½® `OPENAI_API_KEY = "ä½ çš„API key"`
3. è®¾ç½® `TRANSCRIPTION_MODE = "openai_api"`

### æ–¹æ¡ˆäºŒï¼šä½¿ç”¨æœ¬åœ°faster-whisper
```bash
pip install faster-whisper
# ç„¶åŽåœ¨ config.py ä¸­è®¾ç½®:
# TRANSCRIPTION_MODE = "faster_whisper"
```

### æ–¹æ¡ˆä¸‰ï¼šä½¿ç”¨whisper.cpp
```bash
# å®‰è£…whisper.cpp
git clone https://github.com/ggerganov/whisper.cpp
cd whisper.cpp
make
# ä¸‹è½½æ¨¡åž‹
./models/download-ggml-model.sh base
# ç„¶åŽåœ¨ config.py ä¸­è®¾ç½®:
# TRANSCRIPTION_MODE = "whisper_cpp"
```

## ðŸŽ¯ å½“å‰æ–‡ä»¶
éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜ï¼Œå¯ä»¥ä½¿ç”¨ä¸Šè¿°ä»»ä¸€æ–¹æ¡ˆè¿›è¡Œè½¬å½•ã€‚

---
*ç®€åŒ–æ¨¡å¼ - éœ€è¦é…ç½®è½¬å½•åŠŸèƒ½ä»¥èŽ·å–å®Œæ•´æ–‡å­—ç¨¿*
"""

        print("âœ… ç®€åŒ–æ¨¡å¼å®Œæˆï¼ˆéŸ³é¢‘å·²ä¿å­˜ï¼Œæœªè½¬å½•ï¼‰")
        return transcript

    def get_mode_info(self):
        """èŽ·å–å½“å‰è½¬å½•æ¨¡å¼ä¿¡æ¯"""
        info = {
            "current_mode": self.mode,
            "available_modes": self.available_modes,
            "language": self.language,
        }

        if self.mode == "openai_api":
            info["api_configured"] = bool(OPENAI_API_KEY and OPENAI_API_KEY.strip())
            info["model"] = OPENAI_WHISPER_MODEL
        elif self.mode == "faster_whisper":
            info["model_size"] = FASTER_WHISPER_MODEL_SIZE
            info["device"] = FASTER_WHISPER_DEVICE

        return info


# ä¾¿æ·å‡½æ•°
def transcribe_audio(audio_path, podcast_name="", episode_title=""):
    """è½¬å½•éŸ³é¢‘æ–‡ä»¶çš„ä¾¿æ·å‡½æ•°"""
    manager = TranscriptionManager()
    return manager.transcribe(audio_path, podcast_name, episode_title)


def get_transcription_info():
    """èŽ·å–è½¬å½•é…ç½®ä¿¡æ¯"""
    manager = TranscriptionManager()
    return manager.get_mode_info()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import argparse

    parser = argparse.ArgumentParser(description="æµ‹è¯•è½¬å½•æ¨¡å—")
    parser.add_argument("--audio", help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--podcast", default="æµ‹è¯•æ’­å®¢", help="æ’­å®¢åç§°")
    parser.add_argument("--episode", default="æµ‹è¯•æœŸæ•°", help="æœŸæ•°æ ‡é¢˜")

    args = parser.parse_args()

    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("ðŸ“‹ è½¬å½•é…ç½®ä¿¡æ¯:")
    info = get_transcription_info()
    for key, value in info.items():
        print(f"  {key}: {value}")

    print("\n" + "=" * 60)

    if args.audio and os.path.exists(args.audio):
        try:
            transcript = transcribe_audio(args.audio, args.podcast, args.episode)
            print("\nðŸ“ è½¬å½•ç»“æžœé¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
            print("=" * 60)
            print(transcript[:500] + ("..." if len(transcript) > 500 else ""))
            print("=" * 60)
            print(f"æ€»é•¿åº¦: {len(transcript)} å­—ç¬¦")
        except Exception as e:
            print(f"âŒ è½¬å½•å¤±è´¥: {e}")
    else:
        print("ðŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print(
            "  python transcription.py --audio /path/to/audio.mp3 --podcast 'æ’­å®¢å' --episode 'æœŸæ•°æ ‡é¢˜'"
        )
        print("\nðŸ’¡ æµ‹è¯•ç®€åŒ–æ¨¡å¼:")
        print("  echo 'æµ‹è¯•éŸ³é¢‘' > test_audio.txt")
        print("  python transcription.py --audio test_audio.txt")
